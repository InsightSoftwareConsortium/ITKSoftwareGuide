\chapter{Registration}

\begin{floatingfigure}[rlp]{8cm}
  \centering
  \includegraphics[width=8cm]{ImageRegistrationConcept.eps}
  \caption[Image Registration Concept]{Image registration is the task of
finding a spatial transform mapping one image into
another.\label{fig:ImageRegistrationConcept}}
\end{floatingfigure}

This chapter introduces ITK's capabilities for performing image
registration. Image registration is the process of determining the spatial
transform that maps points from one image to homologous points on a object in
the second image. This concept is schematically represented in Figure
\ref{fig:ImageRegistrationConcept}. In ITK, registration is performed within
a framework of pluggable components that can easily be interchanged.  This
flexibility means that a combinatorial variety of registration methods can be
created, allowing users to pick and choose the right tools for their specific
application.


\section{Registration Framework}
Let's begin with a simplified typical registration framework where its components
and their interconnections are shown in Figure \ref{fig:RegistrationComponents}.
The basic input data to the registration process are two images: one is defined
as the \emph{fixed} image $f(\bf{X})$ and the other as the \emph{moving} image
$m(\bf{X})$, where $\bf{X}$ represents a position in N-dimensional space.
Registration is treated as an optimization problem with the goal of finding the
spatial mapping that will bring the moving image into alignment with the fixed image.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{RegistrationComponentsDiagram.eps}
\itkcaption[A Typical Registration Framework Components]{The basic components
of a typical registration framework are two input images, a transform, a
metric, an interpolator and an optimizer.}
\label{fig:RegistrationComponents}
\end{figure}

The \emph{transform} component $T(\bf{X})$ represents the spatial mapping of
points from the fixed image space to points in the moving image space. The
\emph{interpolator} is used to evaluate moving image intensities at non-grid
positions. The \emph{metric} component $S(f,m \circ T)$ provides a measure of
how well the fixed image is matched by the transformed moving image. This
measure forms a quantitative criterion to be optimized by the
\emph{optimizer} over the search space defined by the parameters of the
\emph{transform}.

ITKv4 registration framework provides more flexibility to the above traditional
registration concept. In this new framework, the registration computations can
happen on a physical grid completely different than the fixed image domain having
different sampling density.
This ``sampling domain'' is considered as a new component in the registration
framework known as \textbf{virtual image} that can be an arbitrary set of physical
points, not necessarily a uniform grid of points.

Various ITKv4 registration components are illustrated in Figure
\ref{fig:ITKv4RegistrationComponents}. Boxes with dashed borders show
\emph{data objects}, while those with solid borders show \emph{process objects}.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{ITKv4RegistrationComponentsDiagram.eps}
\itkcaption[Registration Framework Components]{The basic components of the ITKv4
registration framework.}
\label{fig:ITKv4RegistrationComponents}
\end{figure}

The matching Metric class is a key component that controls most parts of the
registration process since it handles fixed, moving and virtual images as well
as fixed and moving transforms and interpolators.

Fixed and moving transforms and interpolators are used by the metric to evaluate
the intensity values of the fixed and moving images at each physical point of the
virtual space. Those intensity values are then used by the metric cost function to
evaluate the fitness value and derivatives, which are passed to the optimizer that
asks the moving transform to update its parameters based on the outputs of the cost
function. Since the moving transform is shared between metric and optimizer,
the above process will be repeated till the convergence criteria are met.

Later in section~\ref{sec:FeaturesOfTheRegistrationFramework} you will get a
better understanding of the behind-the-scenes processes of ITKv4 registration
framework. First, we begin with some simple registration examples.


\section{"Hello World" Registration}
\label{sec:IntroductionImageRegistration}
\input{ImageRegistration1.tex}

\section{Features of the Registration Framework}
\label{sec:FeaturesOfTheRegistrationFramework}

This section presents internals of the registration process in ITKv4.
Understanding what actually happens is necessary to have a correct interpretation
of the results of a registration filter. It also helps to understand the
most common difficulties that users encounter when they start using the ITKv4
registration framework:

\begin{itemize}
\item Registration is done in physical coordinates
\item The direction of the transform maps from the space of the virtual image to that of the moving image
\end{itemize}

These two topics tend to create confusion because they
are implemented in different ways in other systems, and community members tend to
have different expectations regarding how registration should work in ITKv4. The
situation is further complicated by the way most people describe image
operations, as if they were manually performed on a continuous picture on a piece
of paper.

These concepts are discussed in this section through a general example shown in
Figure~\ref{fig:ImageRegistrationCoordinateSystemsDiagram}.

\begin{figure}
\centering
\includegraphics[width=0.75\textwidth]{ImageRegistrationCoordinateSystemsDiagram.eps}
\itkcaption[Registration Coordinate Systems]{Different coordinate systems
involved in the image registration process. Note that the transform being
optimized is the one mapping from the physical space of the \textbf{virtual}
image into the physical space of the \textbf{moving} image.}
\label{fig:ImageRegistrationCoordinateSystemsDiagram}
\end{figure}

Recall that ITKv4 does the registration in ``physical'' space where fixed,
moving and virtual images are placed. Also, note that the term of
virtual image is deceptive here since it does not refer to any actual
image. In fact, the virtual image defines the origin, direction and the
spacing of a space lattice that holds the output resampled image of the
registration process. The virtual pixel lattice is illustrated in green
at the top left side of
Figure~\ref{fig:ImageRegistrationCoordinateSystemsDiagram}.

As shown in this figure, generally there are two transforms involved in the
registration process even though only one of them is being optimized. $T_{vm}$
maps points from physical virtual space onto the physical space of the moving
image, and in the same way $T_{vf}$ finds homologous points between physical
virtual space and the physical space of the fixed image. Note that only
$T_{vm}$ is optimized during the registration process. $T_{vf}$ cannot be
optimized. The fixed transform usually is an identity transform since the
virtual image lattice is commonly defined as the fixed image lattice.

When the registration starts, the algorithm goes through each grid point of the
virtual lattice in a raster sweep. At each point the fixed
and moving transforms find coordinates of the homologous points in the fixed
and moving image physical spaces, and interpolators are used to find the pixel
intensities if mapped points are in non-grid positions. These intensity values
are passed to a cost function to find the current metric value.

Note the direction of the mapping transforms here. For example,
if you consider the $T_{vm}$ transform, confusion often occurs since
the transform shifts a virtual lattice point on the \textbf{positive}
X direction. The visual effect of this mapping, once the moving
image is resampled, is equivalent to manually shifting the moving
image along the \textbf{negative} X direction. In the same way, when
the $T_{vm}$ transform applies a \textbf{clock-wise} rotation to the
virtual space points, the visual effect of this mapping, once the
moving image has been resampled, is equivalent to manually rotating
the moving image \textbf{counter-clock-wise}. The same relationships
also occur with the $T_{vf}$ transform between the virtual space and
the fixed image space.

This mapping direction is chosen because the moving image is resampled
on the grid of the virtual image. In the resampling process,
an algorithm iterates through every pixel of the output image
and computes the intensity assigned to this pixel by
mapping to its location in the moving image.

Instead, if we were to use the transform mapping coordinates from the
moving image physical space into the virtual image physical space,
then the resampling process would not guarantee that every pixel in
the grid of the virtual image would receive one and only one value.
In other words, the resampling would result in an image with
holes and redundant or overlapping pixel values.

As seen in the previous examples, and as corroborated in the remaining
examples in this chapter, the transform computed by the registration
framework can be used directly in the resampling filter in order to
map the moving image onto the discrete grid of the virtual image.

There are exceptional cases in which the transform desired is actually
the inverse transform of the one computed by the ITK registration framework.
Only those cases may require invoking the \code{GetInverse()}
method that most transforms offer. Before attempting this,
read the examples on resampling illustrated in
section~\ref{sec:GeometricalTransformationFilters} in order to
familiarize yourself with the correct interpretation of the transforms.

Now we come back to the situation illustrated in
Figure~\ref{fig:ImageRegistrationCoordinateSystemsDiagram}. This figure shows
the flexibility of the ITKv4 registration framework. We can register two
images with different scales, sizes and resolutions. Also, we can create the
output warped image with any desired size and resolution.

Nevertheless, note that the spatial transform computed during the
registration process does not need to be concerned about a different number
of pixels and different pixel sizes between fixed, moving and output images
because the conversion from index space to the physical space implicitly
takes care of the required scaling factor between the involved images.

One important consequence of this fact is that having the correct image origin,
image pixel size, and image direction is fundamental for the success of the
registration process in ITK, since we need this information to compute the exact
location of each pixel lattice in the physical space; we must make sure
that the correct values for the origin, spacing, and direction of all
fixed, moving and virtual images are provided.

In this example, the spatial transform computed will \textbf{physically} map
the brain from the moving image onto the virtual space and minimize its
difference with the resampled brain from the fixed image into the virtual
space. Fortunately in practice there is no need to resample the fixed image
since the virtual image physical domain is often assumed to be the same as
physical domain of the fixed image.

\section{Monitoring Registration}
\label{sec:MonitoringImageRegistration}
\input{ImageRegistration3.tex}



\section{Multi-Modality Registration}
\label{sec:MultiModalityRegistration}

Some of the most challenging cases of image registration arise when images of
different modalities are involved. In such cases, metrics based on direct
comparison of gray levels are not applicable. It has been extensively shown
that metrics based on the evaluation of mutual information are well suited for
overcoming the difficulties of multi-modality registration.

\index{itk::Image\-Registration\-Method!Multi-Modality}

The concept of Mutual Information is derived from Information Theory and its
application to image registration has been proposed in different forms by
different groups \cite{Collignon1995,Maes97,Viola1997}; a more detailed review
can be found in \cite{Hajnal2001,Pluim2003}. The Insight Toolkit currently
provides two different implementations of Mutual Information metrics (see
section \ref{sec:Metrics} for details). The following example illustrates the
practical use of one of these metrics.

\subsection{Mattes Mutual Information}
\label{sec:MultiModalityRegistrationMattes}
\input{ImageRegistration4.tex}

% #TODO needs updating to new statistics
% \subsection{Plotting joint histograms}
% \label{sec:JointHistograms}
% \input{ImageRegistrationHistogramPlotter.tex}


\section{ Center Initialization }

The ITK image coordinate origin is typically located in one of the image
corners (see the  Defining Origin and Spacing section of Book 1 for details).
This results in counter-intuitive transform behavior when rotations and scaling
are involved. Users tend to assume that rotations and scaling are performed
around a fixed point at the center of the image. In order to compensate for
this difference in expected interpretation, the concept of \emph{center} of
transform has been introduced into the toolkit. This parameter is
generally a \emph{fixed} parameter that is not optimized during
registration, so initialization is crucial to get efficient and
accurate results. The following sections describe the main
characteristics and effects of initializing the center of a
transform.

\subsection{Rigid Registration in 2D}
\label{sec:RigidRegistrationIn2D}
\input{ImageRegistration5.tex}

\subsection{Initializing with Image Moments}
\label{sec:InitializingRegistrationWithMoments}
\input{ImageRegistration6.tex}



\subsection{Similarity Transform in 2D}
\label{sec:SimilarityRegistrationIn2D}
\input{ImageRegistration7.tex}



\subsection{Rigid Transform in 3D}
\label{sec:RigidRegistrationIn3D}
\input{ImageRegistration8.tex}




\subsection{Centered Initialized Affine Transform}
\label{sec:CenteredAffineTransform}
\input{ImageRegistration9.tex}




\section{Multi-Resolution Registration}
\label{sec:MultiResolutionRegistration}
Performing image registration using a multi-resolution approach is widely used
to improve speed, accuracy and robustness. The basic idea is that registration
is first performed at a coarse scale where the images have fewer pixels.
The spatial mapping determined at the coarse level is then used to initialize
registration at the next finer scale. This process is repeated until it
reaches the finest possible scale. This coarse-to-fine strategy greatly
improves the registration success rate and also increases robustness
by eliminating local optima at coarser scales. Robustness can be improved
even more by smoothing the images at coarse scales.

In all previous examples we ran the registration process at a single resolution. However,
the ITKv4 registration framework is structured to provide a multi-resolution registration
method. For this purpose we only need to define the number of levels as well as the
resolution and smoothness of the input images at each level. The registration filter
smoothes and subsamples the images according to user-defined \emph{ShrinkFactor} and
\emph{SmoothingSigma} vectors.

We now present the multi-resolution capabilities of the framework by
way of an example.

\subsection{Fundamentals}
\input{DesignAndFunctionality/ImagePyramids.tex}

\subsection{Fundamentals}
\input{MultiResImageRegistration1.tex}

\section{Multi-Stage Registration}
\label{sec:MultiStageRegistration}
In section \ref{sec:MultiResolutionRegistration} you noticed how to tweak
component settings between multi-resolution levels and saw how it can benefit the
registration process. That is, the matching metric gets close to the optimal
value before final parameter adjustments in full resolution.
This approach saves large amounts of time in most practical
cases, since fewer iterations are required at the full resolution level.
This is helpful in cases like a deformable registration process on a large
dataset, e.g. a high-resolution 3D image.

Another possible scheme is to apply a simple rigid transform for the initial coarse
registration, then upgrade to an affine transform at the finer level. Finally,
proceed to a deformable transform at the last level when we are close enough to
the optimal value.

Fortunately, \doxygen{ImageRegistrationMethodv4} allows for multistage registration
whereby each stage is characterized by possibly different transforms and different
image metrics. As in the above situation, you may want to perform a linear registration
followed by a deformable registration with both stages performed across multiple
resolutions.

Multiple stages are handled by linking multiple instantiations of this class.
An optional composite transform can be used as a container to concatenate
the output transforms of multiple stages.

We now present the multistage capabilities of the framework by way of an example.

\subsection{Fundamentals}
\input{MultiStageImageRegistration1.tex}

\subsection{Cascaded Multistage Registration}
\input{MultiStageImageRegistration2.tex}

With the completion of these examples, we will now review the main
features of the components forming the registration framework.


% This clearpage command is intended to separate the graphics from previous
% examples from the diagrams of this section. This should prevent the
% registration diagrams from getting mixed with the diagrams for the Geometric
% objects used by the Transforms.
\clearpage

\section{Transforms}
\label{sec:Transforms}
\input{DesignAndFunctionality/Transforms.tex}



% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage

\section{Interpolators}
\label{sec:Interpolators}
\input{DesignAndFunctionality/ImageInterpolators.tex}

% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage

\section{Metrics}
\label{sec:Metrics}
\input{DesignAndFunctionality/ImageMetrics.tex}

% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage

\section{Optimizers}
\label{sec:Optimizers}
\input{DesignAndFunctionality/Optimizers.tex}



\subsection{Registration using the One plus One Evolutionary Optimizer}
\label{sec:RegistrationOnePlusOne}
\input{ImageRegistration11.tex}



\subsection{Registration using masks constructed with Spatial objects}
\label{sec:RegistrationSpatialObjects}
\input{ImageRegistration12.tex}



\subsection{Rigid registrations incorporating prior knowledge}
\label{sec:RegistrationCentered2DTransform}
\input{ImageRegistration13.tex}


% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage

\section{Deformable Registration}
\label{sec:DeformableRegistration}
\input{DesignAndFunctionality/DeformableRegistration.tex}

% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage

\section{Demons Deformable Registration}
\label{sec:DemonsDeformableRegistration}
\input{DesignAndFunctionality/DemonsRegistration.tex}

\section{Visualizing Deformation fields}
\label{sec:VisualizingDeformationFields}
\input{DesignAndFunctionality/VisualizingDeformationFieldsUsingParaview.tex}

\input{DesignAndFunctionality/DeformableRegistration4OnBrain.tex}


% the clearpage command helps to avoid orphans in the title of the next
% section.
\clearpage



\section{Model Based Registration}
\label{sec:ModelBasedRegistration}
\input{DesignAndFunctionality/ModelBasedRegistration.tex}


\section{Point Set Registration}
\label{sec:PointSetRegistration}

PointSet-to-PointSet registration is a common problem in medical image
analysis. It usually arises in cases where landmarks are extracted from images
and are used for establishing the spatial correspondence between the images.
This type of registration can be considered to be the simplest case of
feature-based registration. In general terms, feature-based registration is
more efficient than the intensity based method that we have presented so far.
However, feature-base registration brings the new problem of identifying and
extracting the features from the images, which is not a minor challenge.

The two most common scenarios in PointSet to PointSet registration are

\begin{itemize}
\item Two PointSets with the same number of points, and where each point in one
set has a known correspondence to exactly one point in the second set.
\item Two PointSets without known correspondences between the points of one set
and the points of the other. In this case the PointSets may have different
numbers of points.
\end{itemize}

The first case can be solved with a closed form solution when we are dealing
with a Rigid or an Affine Transform~\cite{Horn1987}. This is done in ITK with
the class \doxygen{LandmarkBasedTransformInitializer}. If we are interested in
a deformable Transformation then the problem can be solved with the
\doxygen{KernelTransform} family of classes, which includes Thin Plate Splines
among others~\cite{Rohr2001}. In both circumstances, the availability o f
correspondences between the points make possible to apply a straight forward
solution to the problem.


The classical algorithm for performing PointSet to PointSet registration is the
Iterative Closest Point (ICP) algorithm.  The following examples illustrate how
this can be used in ITK.



\subsection{Point Set Registration in 2D}
\label{sec:PointSetRegistrationIn2D}

\input{IterativeClosestPoint1.tex}




\subsection{Point Set Registration in 3D}
\label{sec:PointSetRegistrationIn3D}

\input{IterativeClosestPoint2.tex}



\subsection{Point Set to Distance Map Metric}
\label{sec:PointSetToDistanceMapMetric}

\input{IterativeClosestPoint3.tex}



\section{Registration Troubleshooting}
So you read the previous sections, you wrote the code, it compiles and links fine,
but when you run it the registration results are not what you were expecting.
In that case, this section is for you. This is a compilation of the most common
problems that users face when performing image registration. It provides explanations
on the potential sources of the problems, and advice on how to deal with those problems.

Most of the material in this section has been taken from frequently asked questions of
the ITK users list.


\subsection{Too many samples outside moving image buffer}


https://public.kitware.com/pipermail/insight-users/2007-March/021442.html

This is a common error message in image registration.

It means that at the current iteration of the optimization,
the two images as so off-registration that their spatial
overlap is not large enough for bringing them back into
registration.

The common causes of this problem are:

\begin{itemize}
\item Poor initialization:    You must initialize the transform properly.
Please familiarize yourself with the \doxygen{CenteredTransformInitializer} class.
\item Optimizer steps too large. If you optimizer takes steps that are too
large, it risks to become unstable and to send the images too far apart.  You
may want to start the optimizer with a maximum step length of 1.0, and only
increase it once you have managed to fine tune all other registration
parameters.

Increasing the step length makes your program faster, but it also makes it more
unstable.



\item Poor set up of the transform parameters scaling.  This is extremely
critical in registration. You must make sure that you balance the relative
difference of scale between the rotation parameters and the translation
parameters.

In typical medical datasets such as CT and MR, translations are measured in
millimeters, and therefore are in the range of -100:100, while rotations are
measured in radians, and therefore they tend to be in the range of   -1:1.


A rotation of 3 radians is catastrophic, while a translation of 3 millimeters
is rather inoffensive.  That difference in scale is the one that must be
accounted for.
\end{itemize}



\subsection{General heuristics for parameter fine-tunning}





https://public.kitware.com/pipermail/insight-users/2007-March/021435.html

Here is some advice on how to fine tune the parameters
of the registration process.


1) Set Maximum step length to 0.1 and do not change it
   until all other parameters are stable.

2) Set Minimum step length to 0.001 and do not change it.

   You could interpret these two parameters as if their
   units were radians. So, 0.1 radian = 5.7 degrees.


3) Number of histogram bins:

    First plot the histogram of your image using the
    example program in

    Insight/Examples/Statistics/ImageHistogram2.cxx

    In that program use first a large number  of bins
    (for example 2000) and identify the different
    populations of intensity level and to what anatomical
    structures they correspond.

    Once you identify the anatomical structures in the
    histogram, then rerun that same program with less
    and less number of bins, until you reach the minimum
    number of bins for which all the tissues that are important
    for your application, are still distinctly differentiated in the
    histogram.  At that point, take that number of bins and
    us it for your Mutual Information metric.


4)  Number of Samples:
    The trade-off with the number of samples is the following:

    a) computation time of registration is linearly proportional
       to the number of samples
                                                                                                                        b) the samples must be enough to significantly populate
                                                                                                                           the joint histogram.
                                                                                                                        c) Once the histogram is populated, there is not much
                                                                                                                           use in adding more samples.
Therefore do the following:

Plot the joint histogram of both images, using the number
of bins that you selected in item (3). You can do this by
modifying the code of the example:

Insight/Examples/Statistics/
ImageMutualInformation1.cxx
you have to change the code to print out the values
of the bins. Then use a plotting program such as gnuplot,
or Matlab, or even Excel and look at the distribution.
The number of samples to take must be enough
for producing the same "appearance" of the joint histogram.
As an arbitrary rule of thumb you may want to start using
a high number of samples (80\% - 100\%). And do not
change it until you have mastered the other parameters
of the registration.  Once you get your registration to converge
you can revisit the number of samples and reduce it in order
to make the registration run faster. You can simply reduce it
until you find that the registration becomes unstable. That's
your critical bound for the minimum number of samples.
Take that number and multiply it by the magic number 1.5,
to send it back to a stable region, or if your application is
really critical, then use an even higher magic number x2.0.

This is just engineering: you figure out what is the minimal
size of a piece of steel that will support a bridge, and then
you enlarge it to keep it away from the critical value.

5)  The MOST critical values of the registration process are the
scaling parameters that define the proportions between
the parameters of the transform. In your case, for an Affine
Transform in 2D, you have 6 parameters. The first four are
the ones of the Matrix, and the last two are the translation.
The rotation matrix value must be in the ranges of radians
which is typically [ -1 to 1 ], while the translation values are
in the ranges of millimeters (your image size units).
You want to start by setting the scaling of the matrix
parameters to 1.0, and the scaling of the Translation
parameters to the holy esoteric values:

1.0   /  (  10.0 * pixelspacing[0]  *  imagesize[0]  )
1.0   /  (  10.0 * pixelspacing[1]  *  imagesize[1]  )

This is telling the optimizer that you consider that rotating
the image by 57 degrees is as "significant" as translating
the image by half its physical extent.

Note that esoteric value has included the arbitrary number
10.0 in the denominator, for no other reason that we have
been lucky when using that factor. This of course is just a
superstition, so you should feel free to experiment with
different values of this number.

Just keep in mind that what the optimizer will do is to
``jump'' in a parametric space of 6 dimensions, and that the
component of the jump on every dimension will be proportional
to 1/scaling factor * OptimizerStepLength.     Since you set
the optimizer Step Length to 0.1, the optimizer will start
by exploring the rotations at jumps of about 5 degrees, which
is a conservative rotation for most medical applications.

If you have reasons to think that your rotations are larger or
smaller, then you should modify the scaling factor of the  matrix
parameters accordingly.

In the same way, if you think that 1/10 of the image size is too
large as the first step for exploring the translations, then you
should modify the scaling of  translation parameters accordingly.



In order to drive all these you need to analyze the feedback that
the observer is providing you. For example, plot the metric values,
and plot the translation coordinates so that you can get a feeling
of how the registration is behaving.


Note also that image registration is not a science. It is a pure
engineerig practice, and therefore, there are no correct answers,
nor ``truths'' to be found. It is all about how much quality you want,
and how must computation time, and development time you are
willing to pay for that quality. The ``satisfying'' answer for your
specific application must be found by exploring the trade-offs
between the different parameters that regulate the image
registration process.

If you are proficient in VTK you may want to consider attaching
some visualization to the Event observer, so that you can have
a visual feedback on the progress of the registration. This is a
lot more productive than trying to interpret the values printed
out on the console by the observer.
